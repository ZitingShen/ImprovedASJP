import re
import csv
from nltk.metrics import edit_distance
from phon_util import ipa_symbols, ipa_diacritics_replace, ipa_diacritics_modify, ipa_joining_bars, ipa_delimiters
from geopy.distance import vincenty
import multiprocessing
from functools import partial

class RegularWord:
	def __init__(self, language, meaning, representation):
		"""
		:param language: the language of this word
		:param meaning: the meaning of this word
		:param representation: the orthographic or phonological representation
							   of this word
		"""
		self.language = language
		self.meaning = meaning
		self.representation = representation.decode('utf-8')
		self.words = [word.decode('utf-8').strip() for word in re.split(ipa_delimiters, representation)]
		self.regularize()

	def regularize(self):
		"""
		Remove the non-regular symbols in IPA.
		:return: a dict of each word's regularized phonetic transcription
		"""
		regular_forms = []

		for word in self.words:
			regular_form = ""
			i = 0
			while i in range(len(word)):
				if word[i] in ipa_symbols:
					regular_form += word[i]
				elif word[i] in ipa_joining_bars:
					i += 1
				elif word[i] == '(':
					i += 1
					while i < len(word) and word[i] != ')':
						i += 1
				i += 1
			regular_forms += [regular_form]
		self.words = regular_forms

def readInPhonologicalData( \
	input='data/Processed Data with Phonological Forms - IELEX.csv'):
	"""
	Read in the filtered swadeshed list in the phonological forms.
	:param input: the file name of the input
	:return: the reader of the input file as a list
	"""
	with open(input) as input_file:
		reader = csv.DictReader(input_file)
		return list(reader)

def convertRegular(input):
	"""
	Convert a list of word phonetic transcriptions to corresponding features.
	:param input: the reader of the input file as a list
	:return: a list of all words in the data which are represented as features
	"""
	words = [RegularWord(item['language_name'], item['word_meaning'], \
			      item['word_phonological_form']) for item in input]
	return words




class LanguageComparer():
	def __init__(self, language1, language2, words_dict, meaning_list):
		"""
		Compute the linguistic distance and geographical distance of language1 and
		language2 using the specified meaning_list.
		:param language1: the name of one of the two languages being compared
		:param language2: the name of the other language being compared
		:param words_dict: a dictionary of dictionary of words from a bag of RegularWord-typed words, 
						   whose keys are the language names and the meanings
		:param meaning_list: the basic vocabulary used to compute the linguistic distance
		"""
		self.language1 = language1
		self.language2 = language2
		self.language1_dict = words_dict[language1]
		self.language2_dict = words_dict[language2]
		self.meaning_list = meaning_list

	def linguistic_distance(self):
		"""
		Compare the two languages word by word for all meanings in the meaning_list.
		:return: the linguistic similarity between the two languages
		"""
		eds = []
		norms = []
		for meaning in self.meaning_list:
			word1 = self.language1_dict.get(meaning)
			word2 = self.language2_dict.get(meaning)
			if word1 != None and word2 != None:
				word1 = word1.words[0]
				word2 = word2.words[0]
				LDN = edit_distance(word1, word2)/float(max(len(word1), len(word2)))
				eds += [LDN]

		for meaning in self.meaning_list:
			for meaning2 in self.meaning_list:
				if meaning != meaning2:
					word1 = self.language1_dict.get(meaning)
					word2 = self.language2_dict.get(meaning2)
					if word1 != None and word2 != None:
						word1 = word1.words[0]
						word2 = word2.words[0]
						LDN = edit_distance(word1, word2)/float(max(len(word1), len(word2)))
						norms += [LDN]

		average = sum(norms)/float(len(norms))
		LDND = [ed/average for ed in eds]
		return sum(LDND)/len(LDND)


def generate_word_dictionary(words_bag, meaning_list='data/40-item Swadesh List.txt'):
	"""
	Generate a dictionary of dictionary of words from a bag of RegularWord-typed words.
	The keys will be the language and the meanings.
	:param words_bag: a bag of all words generated by convertToFeatures(readInPhonologicalData())
					  from phonemes_to_features.py
	:param meaning_list: the basic vocabulary used to compute the linguistic distance
	:return: a dictionary of dictionary of words from a bag of RegularWord-typed words, whose 
			 keys are the language and the meanings
	"""
	words_dict = {}
	for word in words_bag:
		if word.language not in words_dict:
			words_dict[word.language] = {}
		words_dict[word.language][word.meaning] = word
	return words_dict

def compare_languages(languageA, languageB, meaning_input='data/40-item Swadesh List.txt'):
	"""
	Compare a pair of languages that has 100+ words in phonological forms.
	:param languageA: one of the two languages compared
	:param languageB: the other language compared
	:param meaning_list: the basic vocabulary used to compute the linguistic distance
	:return: the distance between languageA and languageB
	"""
	with open(meaning_input) as input:
		meaning_list = [meaning for line in input for meaning in line.split()]
	words_bag = convertRegular(readInPhonologicalData())
	words_dict = generate_word_dictionary(words_bag)

	language_comparer = LanguageComparer(languageA, languageB, words_dict, meaning_list)
	return language_comparer.linguistic_distance()




def calculateDiversity(input='output/Processed Geographical Longitude Latitude - ASJP.csv'):
	long_lat = {}
	diviersities = {}
	with open(input) as input_file:
		reader = csv.DictReader(input_file)
		for row in reader:
			long_lat[row['language']] = (row['longitude'], row['latitude'])

	pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())
	result = pool.map(partial(calculateIndividualDiversity, long_lat=long_lat), list(long_lat.keys()))
	for (language, diversity) in result:
		diviersities[language] = diversity

	for key, value in sorted(diviersities.iteritems(), key=lambda (k,v): (v,k)):
		print "%s: %s" % (key, value)

def calculateIndividualDiversity(language, long_lat):
	diversity = 0.0
	for other_language in long_lat:
		if language == other_language:
			continue
		ling_dist = compare_languages(language, other_language)
		geo_dist = vincenty(long_lat[language], long_lat[other_language]).km
		if geo_dist < 500:
			geo_dist = 500
		#print str(ling_dist) + '\t' + str(geo_dist)
		diversity = diversity + ling_dist/geo_dist
	return (language, diversity)

if __name__ == '__main__':			
	calculateDiversity()
	#print compare_languages('Icelandic', 'English')